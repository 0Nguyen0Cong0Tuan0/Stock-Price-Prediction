{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f5cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import timedelta\n",
    "from scipy.stats import trim_mean\n",
    "import os\n",
    "import logging\n",
    "import cmdstanpy\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Suppress cmdstanpy debug logs to reduce console clutter\n",
    "cmdstanpy.utils.get_logger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32216b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(stock_csv, balance_csv, cashflow_csv, income_csv, ticker):\n",
    "    \"\"\"\n",
    "    Load and preprocess stock and financial data, aligning them for modeling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load stock data\n",
    "        stock_df = pd.read_csv(stock_csv)\n",
    "        stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "        stock_df = stock_df[stock_df['Ticker'] == ticker][['Date', 'Close', 'Volume']].sort_values('Date')\n",
    "        stock_df = stock_df.drop_duplicates(subset='Date')\n",
    "        \n",
    "        # Validate stock data\n",
    "        if stock_df['Close'].min() <= 0:\n",
    "            raise ValueError(\"Invalid stock data: Close prices contain zero or negative values\")\n",
    "        \n",
    "        # Create daily date range and fill missing dates\n",
    "        date_range = pd.date_range(start=stock_df['Date'].min(), end=stock_df['Date'].max(), freq='D')\n",
    "        stock_df = stock_df.set_index('Date').reindex(date_range, method='ffill').reset_index()\n",
    "        stock_df = stock_df.rename(columns={'index': 'Date'})\n",
    "        stock_df['Ticker'] = ticker\n",
    "        \n",
    "        print(f\"Loaded {len(stock_df)} daily stock data points for {ticker}\")\n",
    "        \n",
    "        # Load financial data\n",
    "        balance_df = pd.read_csv(balance_csv)\n",
    "        cashflow_df = pd.read_csv(cashflow_csv)\n",
    "        income_df = pd.read_csv(income_csv)\n",
    "        \n",
    "        # Select key financial metrics\n",
    "        financial_metrics = {\n",
    "            'Diluted EPS': income_df[income_df['index'] == 'Diluted EPS'][['2024-09-30 00:00:00']].iloc[0, 0],\n",
    "            'Free Cash Flow': cashflow_df[cashflow_df['index'] == 'Free Cash Flow'][['2024-09-30 00:00:00']].iloc[0, 0],\n",
    "            'Net Debt': balance_df[balance_df['index'] == 'Net Debt'][['2024-09-30 00:00:00']].iloc[0, 0],\n",
    "            'EBITDA': income_df[income_df['index'] == 'EBITDA'][['2024-09-30 00:00:00']].iloc[0, 0]\n",
    "        }\n",
    "        \n",
    "        # Create financial DataFrame aligned with stock data\n",
    "        financial_df = pd.DataFrame(index=stock_df['Date'])\n",
    "        for metric, value in financial_metrics.items():\n",
    "            financial_df[metric] = value\n",
    "        \n",
    "        # Merge stock and financial data\n",
    "        merged_df = stock_df.merge(financial_df.reset_index(), on='Date', how='left')\n",
    "        merged_df = merged_df.set_index('Date')\n",
    "        \n",
    "        # Scale financial features\n",
    "        scaler = StandardScaler()\n",
    "        financial_cols = ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA']\n",
    "        merged_df[financial_cols] = scaler.fit_transform(merged_df[financial_cols])\n",
    "        \n",
    "        print(f\"Prepared data with {len(merged_df)} rows, including financial features: {list(financial_metrics.keys())}\")\n",
    "        return merged_df, scaler\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57f0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing URLs and special characters.\n",
    "    Added: Text preprocessing for sentiment analysis.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcf515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_news_data(news_csv, ticker, stock_dates):\n",
    "    \"\"\"\n",
    "    Load and preprocess news data, compute sentiment scores, and align with stock data dates.\n",
    "    Adjusted: Neutral fallback sentiment, text cleaning, performance optimization, date validation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(news_csv):\n",
    "            logging.error(f\"News file not found: {news_csv}\")\n",
    "            raise FileNotFoundError(f\"News file not found: {news_csv}\")\n",
    "        \n",
    "        # Load news data\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        logging.info(f\"Raw news data shape: {news_df.shape}, columns: {list(news_df.columns)}\")\n",
    "        \n",
    "        # Parse dates\n",
    "        news_df['Date'] = pd.to_datetime(news_df['Date'])\n",
    "        invalid_dates = news_df['Date'].isna().sum()\n",
    "        if invalid_dates > 0:\n",
    "            logging.warning(f\"Dropped {invalid_dates} rows due to invalid dates\")\n",
    "        news_df = news_df.dropna(subset=['Date'])\n",
    "        logging.info(f\"After date parsing, news data shape: {news_df.shape}\")\n",
    "        \n",
    "        # Filter for ticker\n",
    "        news_df['Ticker'] = news_df['Ticker'].str.strip().str.upper()\n",
    "        ticker = ticker.strip().upper()\n",
    "        news_df = news_df[news_df['Ticker'] == ticker]\n",
    "        logging.info(f\"After filtering for ticker '{ticker}', news data shape: {news_df.shape}\")\n",
    "        \n",
    "        if news_df.empty:\n",
    "            logging.warning(f\"No news articles found for {ticker}. Using neutral sentiment scores.\")\n",
    "            return pd.DataFrame({'Date': stock_dates, 'Sentiment_Score': 0.0})\n",
    "        \n",
    "        # Initialize sentiment analyzer\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Compute sentiment with progress bar\n",
    "        def get_sentiment(row):\n",
    "            text = (clean_text(row['Content']) if pd.notna(row['Content']) else\n",
    "                    clean_text(row['Description']) if pd.notna(row['Description']) else\n",
    "                    clean_text(row['Title']) if pd.notna(row['Title']) else \"\")\n",
    "            if not text:\n",
    "                logging.debug(f\"Empty text for row: {row.name}. Returning 0.0\")\n",
    "                return 0.0\n",
    "            scores = analyzer.polarity_scores(text)\n",
    "            return scores['compound']\n",
    "        \n",
    "        news_df['Sentiment_Score'] = [get_sentiment(row) for row in tqdm(news_df.to_dict('records'), desc=\"Sentiment Analysis\")]\n",
    "        logging.info(f\"Sentiment score summary: {news_df['Sentiment_Score'].describe().to_dict()}\")\n",
    "        \n",
    "        # Aggregate sentiment by date\n",
    "        sentiment_df = news_df.groupby('Date')['Sentiment_Score'].mean().reset_index()\n",
    "        sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])\n",
    "        logging.info(f\"Aggregated sentiment data shape: {sentiment_df.shape}\")\n",
    "        \n",
    "        # Create full sentiment DataFrame\n",
    "        sentiment_full = pd.DataFrame({'Date': stock_dates, 'Sentiment_Score': 0.0})\n",
    "        sentiment_full = sentiment_full.merge(sentiment_df, on='Date', how='left', suffixes=('', '_news'))\n",
    "        sentiment_full['Sentiment_Score'] = sentiment_full['Sentiment_Score_news'].fillna(0.0)\n",
    "        \n",
    "        # Forward-fill sentiment after first non-zero score\n",
    "        first_news_date = sentiment_full[sentiment_full['Sentiment_Score'] != 0.0]['Date'].min()\n",
    "        if pd.notna(first_news_date):\n",
    "            mask = sentiment_full['Date'] >= first_news_date\n",
    "            sentiment_full.loc[mask, 'Sentiment_Score'] = sentiment_full.loc[mask, 'Sentiment_Score'].ffill()\n",
    "        \n",
    "        sentiment_full = sentiment_full[['Date', 'Sentiment_Score']]\n",
    "        logging.info(f\"Final sentiment data shape: {sentiment_full.shape}, non-zero scores: {sentiment_full['Sentiment_Score'].ne(0).sum()}\")\n",
    "        return sentiment_full\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"File not found: {e}\")\n",
    "        return pd.DataFrame({'Date': stock_dates, 'Sentiment_Score': 0.0})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing news data: {e}\")\n",
    "        return pd.DataFrame({'Date': stock_dates, 'Sentiment_Score': 0.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118dbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate RMSE, MAE, and MAPE for model evaluation.\n",
    "    Adjusted: Log filtered data points.\n",
    "    \"\"\"\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    mask = (actual > 0) & (~np.isnan(actual)) & (~np.isnan(predicted))\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "    \n",
    "    if len(actual) < len(np.array(actual, copy=True)):\n",
    "        logging.info(f\"Filtered {len(np.array(actual, copy=True)) - len(actual)} invalid data points for metrics calculation\")\n",
    "    \n",
    "    if len(actual) == 0:\n",
    "        logging.warning(\"No valid data for metrics calculation\")\n",
    "        return {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan}\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100 if np.all(actual != 0) else np.nan\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a6385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecast(data, forecast_horizon=7):\n",
    "    \"\"\"\n",
    "    Fit ARIMA model with stationarity check.\n",
    "    Adjusted: Validate data, handle insufficient data, robust error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate data\n",
    "        data = data.dropna()\n",
    "        if data.isna().any() or np.isinf(data).any():\n",
    "            logging.error(\"Invalid data: Contains NaN or inf values\")\n",
    "            return None, None, None\n",
    "        if len(data) < 30:\n",
    "            logging.error(\"Insufficient data for ARIMA (<30 days)\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Check stationarity\n",
    "        result = adfuller(data)\n",
    "        if result[1] > 0.05:\n",
    "            logging.info(\"Data is non-stationary, applying differencing\")\n",
    "            data_diff = data.diff().dropna()\n",
    "            if len(data_diff) < 10:\n",
    "                logging.error(\"Insufficient data after differencing\")\n",
    "                return None, None, None\n",
    "            model = auto_arima(data_diff, seasonal=False, max_p=7, max_q=7, max_d=2,\n",
    "                              stepwise=True, trace=True, error_action='ignore')\n",
    "            best_order = model.order\n",
    "            arima_model = ARIMA(data_diff, order=best_order).fit()\n",
    "            forecast_diff = arima_model.forecast(steps=forecast_horizon)\n",
    "            forecast = data.iloc[-1] + forecast_diff.cumsum()\n",
    "        else:\n",
    "            model = auto_arima(data, seasonal=False, max_p=7, max_q=7, max_d=2,\n",
    "                              stepwise=True, trace=True, error_action='ignore')\n",
    "            best_order = model.order\n",
    "            arima_model = ARIMA(data, order=best_order).fit()\n",
    "            forecast = arima_model.forecast(steps=forecast_horizon)\n",
    "        \n",
    "        # Evaluate\n",
    "        if len(data) >= forecast_horizon:\n",
    "            test_data = data[-forecast_horizon:]\n",
    "            forecast_test = arima_model.forecast(steps=forecast_horizon)[-forecast_horizon:]\n",
    "            metrics = calculate_metrics(test_data, forecast_test)\n",
    "        else:\n",
    "            metrics = {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan}\n",
    "        \n",
    "        logging.info(f\"ARIMA Metrics: {metrics}\")\n",
    "        return forecast, metrics, best_order\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in ARIMA forecasting: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73566462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_forecast(data, forecast_horizon=7, changepoint_prior_scale=0.05):\n",
    "    \"\"\"\n",
    "    Fit Prophet model with dynamic regressors.\n",
    "    Adjusted: Forecast regressors, handle duplicates, enable MCMC for small datasets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Prophet input DataFrame columns: {list(data.columns)}\")\n",
    "        prophet_df = data.reset_index()[['Date', 'Close', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']]\n",
    "        prophet_df = prophet_df.drop_duplicates(subset='Date')\n",
    "        prophet_df = prophet_df.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        \n",
    "        logging.info(f\"Prophet input data summary:\\n{prophet_df.describe()}\")\n",
    "        \n",
    "        # Fit Prophet model\n",
    "        model = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True,\n",
    "                       changepoint_prior_scale=changepoint_prior_scale, mcmc_samples=300 if len(prophet_df) < 1000 else 0)\n",
    "        for regressor in ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']:\n",
    "            model.add_regressor(regressor)\n",
    "        model.fit(prophet_df)\n",
    "        \n",
    "        # Create future dataframe with dynamic regressors\n",
    "        future = model.make_future_dataframe(periods=forecast_horizon)\n",
    "        for regressor in ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA']:\n",
    "            future[regressor] = prophet_df[regressor].mean()  # Use mean of historical data\n",
    "        future['Sentiment_Score'] = prophet_df['Sentiment_Score'].iloc[-10:].mean()  # Recent sentiment trend\n",
    "        forecast_df = model.predict(future)\n",
    "        \n",
    "        # Extract forecast\n",
    "        forecast = forecast_df[['ds', 'yhat']].tail(forecast_horizon).set_index('ds')['yhat']\n",
    "        \n",
    "        # Evaluate\n",
    "        test_data = prophet_df['y'][-forecast_horizon:]\n",
    "        forecast_test = model.predict(prophet_df[-forecast_horizon:])['yhat']\n",
    "        metrics = calculate_metrics(test_data, forecast_test)\n",
    "        \n",
    "        logging.info(f\"Prophet Metrics (changepoint_prior_scale={changepoint_prior_scale}): {metrics}\")\n",
    "        return forecast, metrics, forecast_df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in Prophet forecasting: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f50252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_prophet(data, forecast_horizon=7):\n",
    "    \"\"\"\n",
    "    Tune Prophet model by testing changepoint_prior_scale values.\n",
    "    \"\"\"\n",
    "    scales = [0.05, 0.1, 0.5]\n",
    "    best_metrics = {'RMSE': float('inf')}\n",
    "    best_forecast = None\n",
    "    best_forecast_df = None\n",
    "    best_scale = 0.05\n",
    "    \n",
    "    for scale in scales:\n",
    "        try:\n",
    "            forecast, metrics, forecast_df = prophet_forecast(data, forecast_horizon, changepoint_prior_scale=scale)\n",
    "            if forecast is not None and metrics is not None and not np.any(np.isnan(forecast)):\n",
    "                logging.info(f\"Prophet Metrics (changepoint_prior_scale={scale}): {metrics}\")\n",
    "                if metrics['RMSE'] < best_metrics['RMSE']:\n",
    "                    best_metrics = metrics\n",
    "                    best_forecast = forecast\n",
    "                    best_forecast_df = forecast_df\n",
    "                    best_scale = scale\n",
    "            else:\n",
    "                logging.warning(f\"Prophet failed for scale={scale}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Prophet failed for scale={scale}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if best_forecast is None:\n",
    "        logging.warning(\"All Prophet models failed. Using default scale=0.05.\")\n",
    "        forecast, metrics, forecast_df = prophet_forecast(data, forecast_horizon, changepoint_prior_scale=0.05)\n",
    "        best_metrics = metrics if metrics else {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan}\n",
    "        best_forecast = forecast\n",
    "        best_forecast_df = forecast_df\n",
    "        best_scale = 0.05\n",
    "    \n",
    "    logging.info(f\"Best Prophet changepoint_prior_scale: {best_scale}\")\n",
    "    logging.info(f\"Best Prophet Metrics: {best_metrics}\")\n",
    "    return best_forecast, best_metrics, best_forecast_df, best_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f710387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(data, predictions, model_name, threshold=None):\n",
    "    \"\"\"\n",
    "    Backtest a trading strategy with volatility-based threshold.\n",
    "    Adjusted: Volatility-based threshold, prevent lookahead bias, add transaction costs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Backtest input lengths - Data: {len(data)}, Predictions: {len(predictions)}\")\n",
    "        if len(predictions) != len(data):\n",
    "            logging.warning(f\"Predictions length ({len(predictions)}) does not match data length ({len(data)}). Truncating.\")\n",
    "            min_length = min(len(data), len(predictions))\n",
    "            data = data.iloc[:min_length]\n",
    "            predictions = predictions[:min_length]\n",
    "        \n",
    "        pred_df = pd.DataFrame({'Date': data.index, 'Close': data['Close'], 'Prediction': predictions})\n",
    "        pred_df = pred_df.dropna()\n",
    "        \n",
    "        # Volatility-based threshold\n",
    "        volatility = pred_df['Close'].pct_change().std()\n",
    "        threshold = volatility * 2 if threshold is None else threshold\n",
    "        \n",
    "        # Generate signals without lookahead bias\n",
    "        pred_df['Signal'] = 0\n",
    "        pred_df.loc[1:, 'Signal'] = np.where(\n",
    "            pred_df['Prediction'][1:] > pred_df['Close'][:-1] * (1 + threshold), 1,\n",
    "            np.where(pred_df['Prediction'][1:] < pred_df['Close'][:-1] * (1 - threshold), -1, 0)\n",
    "        )\n",
    "        \n",
    "        # Calculate returns with transaction costs\n",
    "        pred_df['Return'] = pred_df['Close'].pct_change()\n",
    "        transaction_cost = 0.001  # 0.1% per trade\n",
    "        pred_df['Strategy_Return'] = pred_df['Signal'].shift(1) * pred_df['Return'] - \\\n",
    "                                    pred_df['Signal'].abs().shift(1) * transaction_cost\n",
    "        \n",
    "        # Cumulative return\n",
    "        cumulative_return = (1 + pred_df['Strategy_Return'].dropna()).cumprod().iloc[-1] - 1\n",
    "        num_trades = pred_df['Signal'].abs().sum()\n",
    "        \n",
    "        results = {\n",
    "            'Cumulative Return (%)': cumulative_return * 100,\n",
    "            'Number of Trades': num_trades\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Backtest Results for {model_name}: {results}\")\n",
    "        return results, pred_df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in backtesting: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ceff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(data, forecast_horizon=7, n_folds=10):\n",
    "    \"\"\"\n",
    "    Perform walk-forward validation with robust averaging.\n",
    "    Adjusted: Increase folds, handle missing regressors, robust averaging.\n",
    "    \"\"\"\n",
    "    n_folds = min(n_folds, len(data) // forecast_horizon)\n",
    "    arima_metrics_list = []\n",
    "    prophet_metrics_list = []\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        train_end = len(data) - (n_folds - i) * forecast_horizon\n",
    "        if train_end <= forecast_horizon:\n",
    "            continue\n",
    "        \n",
    "        train_data = data.iloc[:train_end]\n",
    "        test_data = data.iloc[train_end:train_end + forecast_horizon]['Close']\n",
    "        \n",
    "        if len(test_data) != forecast_horizon:\n",
    "            continue\n",
    "        \n",
    "        # ARIMA\n",
    "        arima_model = auto_arima(train_data['Close'], seasonal=False, max_p=7, max_q=7, max_d=2,\n",
    "                                stepwise=True, error_action='ignore')\n",
    "        arima_fit = ARIMA(train_data['Close'], order=arima_model.order).fit()\n",
    "        arima_pred = arima_fit.forecast(steps=forecast_horizon)\n",
    "        arima_metrics = calculate_metrics(test_data, arima_pred)\n",
    "        arima_metrics_list.append(arima_metrics)\n",
    "        \n",
    "        # Prophet\n",
    "        prophet_df = train_data.reset_index()[['Date', 'Close', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']]\n",
    "        prophet_df = prophet_df.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        \n",
    "        prophet_model = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True,\n",
    "                               changepoint_prior_scale=0.05, mcmc_samples=0)\n",
    "        for regressor in ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']:\n",
    "            prophet_model.add_regressor(regressor)\n",
    "        prophet_model.fit(prophet_df)\n",
    "        future = prophet_model.make_future_dataframe(periods=forecast_horizon)\n",
    "        for regressor in ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']:\n",
    "            future[regressor] = prophet_df[regressor].ffill().iloc[-1]\n",
    "        prophet_pred_df = prophet_model.predict(future)\n",
    "        prophet_pred = prophet_pred_df['yhat'].tail(forecast_horizon)\n",
    "        prophet_metrics = calculate_metrics(test_data, prophet_pred)\n",
    "        prophet_metrics_list.append(prophet_metrics)\n",
    "    \n",
    "    # Robust averaging\n",
    "    avg_metrics = {\n",
    "        'ARIMA': {\n",
    "            'RMSE': trim_mean([m['RMSE'] for m in arima_metrics_list], proportiontocut=0.1) if arima_metrics_list else np.nan,\n",
    "            'MAE': trim_mean([m['MAE'] for m in arima_metrics_list], proportiontocut=0.1) if arima_metrics_list else np.nan,\n",
    "            'MAPE': trim_mean([m['MAPE'] for m in arima_metrics_list if not np.isnan(m['MAPE'])], proportiontocut=0.1) if any(not np.isnan(m['MAPE']) for m in arima_metrics_list) else np.nan\n",
    "        },\n",
    "        'Prophet': {\n",
    "            'RMSE': trim_mean([m['RMSE'] for m in prophet_metrics_list], proportiontocut=0.1) if prophet_metrics_list else np.nan,\n",
    "            'MAE': trim_mean([m['MAE'] for m in prophet_metrics_list], proportiontocut=0.1) if prophet_metrics_list else np.nan,\n",
    "            'MAPE': trim_mean([m['MAPE'] for m in prophet_metrics_list if not np.isnan(m['MAPE'])], proportiontocut=0.1) if any(not np.isnan(m['MAPE']) for m in prophet_metrics_list) else np.nan\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    logging.info(f\"Walk-Forward Validation Results: {avg_metrics}\")\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd6c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(data, arima_forecast, prophet_forecast, prophet_forecast_df, backtest_arima_df, backtest_prophet_df, ticker, forecast_horizon=7):\n",
    "    \"\"\"\n",
    "    Plot predictions with dynamic titles and interactive sentiment visualization using Plotly.\n",
    "    Adjusted: Uses scatter points for significant sentiment, interactive subplots, saves HTML and PNG.\n",
    "    \"\"\"\n",
    "    # Calculate future dates\n",
    "    last_date = data.index[-1]\n",
    "    future_dates = [last_date + timedelta(days=i+1) for i in range(forecast_horizon)]\n",
    "    \n",
    "    # Create 1x2 subplot with secondary y-axes\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=(f'ARIMA: {ticker} Stock Price Prediction', \n",
    "                                        f'Prophet: {ticker} Stock Price Prediction'),\n",
    "                        shared_yaxes=True,\n",
    "                        specs=[[{'secondary_y': True}, {'secondary_y': True}]])\n",
    "    \n",
    "    # --- ARIMA Subplot (Left, Column 1) ---\n",
    "    # Historical Close\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=data.index, y=data['Close'], name='Historical Close', line=dict(color='blue')),\n",
    "        row=1, col=1, secondary_y=False\n",
    "    )\n",
    "    \n",
    "    # ARIMA Forecast\n",
    "    if arima_forecast is not None:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=future_dates, y=arima_forecast, name='ARIMA Forecast', \n",
    "                       line=dict(color='red', dash='dash')),\n",
    "            row=1, col=1, secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # ARIMA Buy/Sell Signals\n",
    "    if backtest_arima_df is not None:\n",
    "        buy_signals = backtest_arima_df[backtest_arima_df['Signal'] == 1]\n",
    "        sell_signals = backtest_arima_df[backtest_arima_df['Signal'] == -1]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=buy_signals['Date'], y=buy_signals['Close'], name='ARIMA Buy Signal',\n",
    "                       mode='markers', marker=dict(color='green', symbol='triangle-up', size=10, opacity=0.7)),\n",
    "            row=1, col=1, secondary_y=False\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=sell_signals['Date'], y=sell_signals['Close'], name='ARIMA Sell Signal',\n",
    "                       mode='markers', marker=dict(color='red', symbol='triangle-down', size=10, opacity=0.7)),\n",
    "            row=1, col=1, secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # Sentiment Scores (Scatter Points)\n",
    "    if 'Sentiment_Score' in data.columns:\n",
    "        sentiment_mask = (data['Sentiment_Score'] != 0.0) & (data['Sentiment_Score'].abs() > 0.3)\n",
    "        if sentiment_mask.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data.index[sentiment_mask], \n",
    "                    y=data['Sentiment_Score'][sentiment_mask],\n",
    "                    name='Significant Sentiment',\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='purple', size=8, opacity=0.5),\n",
    "                    text=[f\"Score: {s:.2f}\" for s in data['Sentiment_Score'][sentiment_mask]],\n",
    "                    hoverinfo='x+text'\n",
    "                ),\n",
    "                row=1, col=1, secondary_y=True\n",
    "            )\n",
    "    \n",
    "    # Historical Close\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=data.index, y=data['Close'], name='Historical Close', line=dict(color='blue'), showlegend=False),\n",
    "        row=1, col=2, secondary_y=False\n",
    "    )\n",
    "    \n",
    "    # Prophet Forecast\n",
    "    if prophet_forecast is not None:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=future_dates, y=prophet_forecast, name='Prophet Forecast', \n",
    "                       line=dict(color='green', dash='dash')),\n",
    "            row=1, col=2, secondary_y=False\n",
    "        )\n",
    "        # Confidence Interval\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=future_dates + future_dates[::-1],\n",
    "                y=list(prophet_forecast_df['yhat_upper'].tail(forecast_horizon)) + \n",
    "                  list(prophet_forecast_df['yhat_lower'].tail(forecast_horizon))[::-1],\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(0, 128, 0, 0.1)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                name='Prophet Confidence Interval',\n",
    "                hoverinfo='skip'\n",
    "            ),\n",
    "            row=1, col=2, secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # Prophet Buy/Sell Signals\n",
    "    if backtest_prophet_df is not None:\n",
    "        buy_signals = backtest_prophet_df[backtest_prophet_df['Signal'] == 1]\n",
    "        sell_signals = backtest_prophet_df[backtest_prophet_df['Signal'] == -1]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=buy_signals['Date'], y=buy_signals['Close'], name='Prophet Buy Signal',\n",
    "                       mode='markers', marker=dict(color='lime', symbol='triangle-up', size=10, opacity=0.7)),\n",
    "            row=1, col=2, secondary_y=False\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=sell_signals['Date'], y=sell_signals['Close'], name='Prophet Sell Signal',\n",
    "                       mode='markers', marker=dict(color='darkred', symbol='triangle-down', size=10, opacity=0.7)),\n",
    "            row=1, col=2, secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # Sentiment Scores (Scatter Points)\n",
    "    if 'Sentiment_Score' in data.columns:\n",
    "        if sentiment_mask.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data.index[sentiment_mask], \n",
    "                    y=data['Sentiment_Score'][sentiment_mask],\n",
    "                    name='Significant Sentiment',\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='purple', size=8, opacity=0.5),\n",
    "                    text=[f\"Score: {s:.2f}\" for s in data['Sentiment_Score'][sentiment_mask]],\n",
    "                    hoverinfo='x+text',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2, secondary_y=True\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=dict(text=f'{ticker} Stock Price Prediction and Backtest Signals (7-Day Forecast)', \n",
    "                   x=0.5, xanchor='center', y=0.98),\n",
    "        height=600, width=1200,\n",
    "        showlegend=True,\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=-0.2, xanchor='center', x=0.5),\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    fig.update_yaxes(title_text='Close Price (USD)', row=1, col=1, secondary_y=False)\n",
    "    fig.update_yaxes(title_text='Sentiment Score (-1 to 1)', row=1, col=1, secondary_y=True, \n",
    "                     showgrid=False, tickfont=dict(color='purple'))\n",
    "    fig.update_yaxes(title_text='Close Price (USD)', row=1, col=2, secondary_y=False)\n",
    "    fig.update_yaxes(title_text='Sentiment Score (-1 to 1)', row=1, col=2, secondary_y=True, \n",
    "                     showgrid=False, tickfont=dict(color='purple'))\n",
    "    \n",
    "    # Add range slider and selectors\n",
    "    fig.update_xaxes(\n",
    "        rangeslider_visible=True,\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
    "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
    "                dict(count=1, label='1y', step='year', stepmode='backward'),\n",
    "                dict(step='all', label='All')\n",
    "            ])\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        rangeslider_visible=True,\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
    "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
    "                dict(count=1, label='1y', step='year', stepmode='backward'),\n",
    "                dict(step='all', label='All')\n",
    "            ])\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Save interactive HTML and static PNG\n",
    "    fig.write_image(f'{ticker}_stock_price_predictions.png', scale=2) \n",
    "    \n",
    "    # Display in notebook\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd12266",
   "metadata": {},
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd031d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 22:03:23,810 - INFO - Set CMDSTAN directory to C:\\Users\\nguye/.cmdstan\n",
      "2025-05-05 22:03:23,817 - INFO - Processing ticker: AAPL\n",
      "2025-05-05 22:03:23,854 - INFO - Raw news data shape: (200, 7), columns: ['Ticker', 'Date', 'Title', 'Description', 'Source', 'URL', 'Content']\n",
      "2025-05-05 22:03:23,854 - INFO - After date parsing, news data shape: (200, 7)\n",
      "2025-05-05 22:03:23,854 - INFO - After filtering for ticker 'AAPL', news data shape: (200, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 726 daily stock data points for AAPL\n",
      "Prepared data with 726 rows, including financial features: ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 100%|██████████| 200/200 [00:02<00:00, 84.11it/s]\n",
      "2025-05-05 22:03:26,253 - INFO - Sentiment score summary: {'count': 200.0, 'mean': 0.6353595, 'std': 0.5866429150331083, 'min': -0.9746, '25%': 0.33455, '50%': 0.9899, '75%': 0.9982, 'max': 0.9996}\n",
      "2025-05-05 22:03:26,253 - INFO - Aggregated sentiment data shape: (5, 2)\n",
      "2025-05-05 22:03:26,253 - INFO - Final sentiment data shape: (726, 2), non-zero scores: 5\n",
      "2025-05-05 22:03:26,253 - INFO - Added Sentiment_Score to data for AAPL. Columns: ['Close', 'Volume', 'Ticker', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "forecast_horizon = 7\n",
    "data_dir = Path('../data')\n",
    "stock_csv = data_dir / 'cleaned_stock_data.csv'\n",
    "\n",
    "# Configure cmdstanpy\n",
    "cmdstan_dir = os.path.expanduser('~/.cmdstan')\n",
    "os.makedirs(cmdstan_dir, exist_ok=True)\n",
    "os.environ['CMDSTAN'] = cmdstan_dir\n",
    "logging.info(f\"Set CMDSTAN directory to {cmdstan_dir}\")\n",
    "\n",
    "# Get tickers\n",
    "tickers = pd.read_csv(stock_csv)['Ticker'].unique()[:5]  # Process up to 5 tickers\n",
    "results = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    logging.info(f\"Processing ticker: {ticker}\")\n",
    "    balance_csv = data_dir / f'balance_sheet_{ticker}.csv'\n",
    "    cashflow_csv = data_dir / f'cash_flow_{ticker}.csv'\n",
    "    income_csv = data_dir / f'income_statement_{ticker}.csv'\n",
    "    news_csv = data_dir / 'news_data.csv'\n",
    "    \n",
    "    # Load and prepare data\n",
    "    data, scaler = load_and_prepare_data(stock_csv, balance_csv, cashflow_csv, income_csv, ticker)\n",
    "    \n",
    "    # Load news data and merge\n",
    "    sentiment_df = load_news_data(news_csv, ticker, data.index)\n",
    "    if sentiment_df is not None:\n",
    "        data = data.reset_index().merge(sentiment_df[['Date', 'Sentiment_Score']], on='Date', how='left')\n",
    "        data['Sentiment_Score'] = data['Sentiment_Score'].fillna(0.0)\n",
    "        data = data.set_index('Date')\n",
    "        logging.info(f\"Added Sentiment_Score to data for {ticker}. Columns: {list(data.columns)}\")\n",
    "    else:\n",
    "        logging.warning(f\"No sentiment data for {ticker}. Using neutral scores.\")\n",
    "        data['Sentiment_Score'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a72f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Free Cash Flow</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>173.500</td>\n",
       "      <td>55962634.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-09</th>\n",
       "      <td>171.770</td>\n",
       "      <td>45326874.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10</th>\n",
       "      <td>173.555</td>\n",
       "      <td>53724501.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>173.750</td>\n",
       "      <td>49473076.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>172.570</td>\n",
       "      <td>45533138.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-28</th>\n",
       "      <td>210.140</td>\n",
       "      <td>38737224.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29</th>\n",
       "      <td>211.210</td>\n",
       "      <td>36827633.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-30</th>\n",
       "      <td>212.500</td>\n",
       "      <td>52286454.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01</th>\n",
       "      <td>213.320</td>\n",
       "      <td>57364925.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-02</th>\n",
       "      <td>205.350</td>\n",
       "      <td>101010621.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>726 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close       Volume Ticker  Diluted EPS  Free Cash Flow  \\\n",
       "Date                                                                   \n",
       "2023-05-08  173.500   55962634.0   AAPL          0.0             0.0   \n",
       "2023-05-09  171.770   45326874.0   AAPL          0.0             0.0   \n",
       "2023-05-10  173.555   53724501.0   AAPL          0.0             0.0   \n",
       "2023-05-11  173.750   49473076.0   AAPL          0.0             0.0   \n",
       "2023-05-12  172.570   45533138.0   AAPL          0.0             0.0   \n",
       "...             ...          ...    ...          ...             ...   \n",
       "2025-04-28  210.140   38737224.0   AAPL          0.0             0.0   \n",
       "2025-04-29  211.210   36827633.0   AAPL          0.0             0.0   \n",
       "2025-04-30  212.500   52286454.0   AAPL          0.0             0.0   \n",
       "2025-05-01  213.320   57364925.0   AAPL          0.0             0.0   \n",
       "2025-05-02  205.350  101010621.0   AAPL          0.0             0.0   \n",
       "\n",
       "            Net Debt  EBITDA  Sentiment_Score  \n",
       "Date                                           \n",
       "2023-05-08       0.0     0.0         0.000000  \n",
       "2023-05-09       0.0     0.0         0.000000  \n",
       "2023-05-10       0.0     0.0         0.000000  \n",
       "2023-05-11       0.0     0.0         0.000000  \n",
       "2023-05-12       0.0     0.0         0.000000  \n",
       "...              ...     ...              ...  \n",
       "2025-04-28       0.0     0.0         0.804225  \n",
       "2025-04-29       0.0     0.0         0.803630  \n",
       "2025-04-30       0.0     0.0         0.756735  \n",
       "2025-05-01       0.0     0.0         0.500205  \n",
       "2025-05-02       0.0     0.0         0.589509  \n",
       "\n",
       "[726 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f68a4",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe36325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:56:42,253 - INFO - Data is non-stationary, applying differencing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(0,0,0)[0]             : AIC=3639.272, Time=0.17 sec\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=3655.321, Time=0.01 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=3646.713, Time=0.02 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=3646.090, Time=0.03 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0]             : AIC=3643.767, Time=0.09 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=3641.632, Time=0.08 sec\n",
      " ARIMA(3,0,2)(0,0,0)[0]             : AIC=3640.161, Time=0.16 sec\n",
      " ARIMA(2,0,3)(0,0,0)[0]             : AIC=3639.780, Time=0.09 sec\n",
      " ARIMA(1,0,1)(0,0,0)[0]             : AIC=3648.085, Time=0.04 sec\n",
      " ARIMA(1,0,3)(0,0,0)[0]             : AIC=3637.914, Time=0.09 sec\n",
      " ARIMA(0,0,3)(0,0,0)[0]             : AIC=3637.281, Time=0.04 sec\n",
      " ARIMA(0,0,2)(0,0,0)[0]             : AIC=3648.073, Time=0.03 sec\n",
      " ARIMA(0,0,4)(0,0,0)[0]             : AIC=3637.470, Time=0.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "2025-05-05 21:56:43,498 - INFO - ARIMA Metrics: {'RMSE': 210.11717332126253, 'MAE': 210.1029578810291, 'MAPE': 99.97586966264268}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,0,4)(0,0,0)[0]             : AIC=3638.421, Time=0.16 sec\n",
      " ARIMA(0,0,3)(0,0,0)[0] intercept   : AIC=3639.109, Time=0.08 sec\n",
      "\n",
      "Best model:  ARIMA(0,0,3)(0,0,0)[0]          \n",
      "Total fit time: 1.171 seconds\n"
     ]
    }
   ],
   "source": [
    "# ARIMA forecast\n",
    "arima_forecast, arima_metrics, arima_order = arima_forecast(data['Close'], forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060ab632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:56:43,514 - INFO - Prophet input DataFrame columns: ['Close', 'Volume', 'Ticker', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']\n",
      "2025-05-05 21:56:43,543 - INFO - Prophet input data summary:\n",
      "                        ds           y  Diluted EPS  Free Cash Flow  Net Debt  \\\n",
      "count                  726  726.000000        726.0           726.0     726.0   \n",
      "mean   2024-05-04 12:00:00  202.270620          0.0             0.0       0.0   \n",
      "min    2023-05-08 00:00:00  165.000000          0.0             0.0       0.0   \n",
      "25%    2023-11-05 06:00:00  180.950000          0.0             0.0       0.0   \n",
      "50%    2024-05-04 12:00:00  193.500000          0.0             0.0       0.0   \n",
      "75%    2024-11-01 18:00:00  225.860000          0.0             0.0       0.0   \n",
      "max    2025-05-02 00:00:00  259.020000          0.0             0.0       0.0   \n",
      "std                    NaN   24.831609          0.0             0.0       0.0   \n",
      "\n",
      "       EBITDA  Sentiment_Score  \n",
      "count   726.0       726.000000  \n",
      "mean      0.0         0.004758  \n",
      "min       0.0         0.000000  \n",
      "25%       0.0         0.000000  \n",
      "50%       0.0         0.000000  \n",
      "75%       0.0         0.000000  \n",
      "max       0.0         0.804225  \n",
      "std       0.0         0.058091  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197a09cea528476ead115074965a3d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54860223d47b446686ae65861d34bf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdab7a766a24f099a93a8339a21435d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d3cd4acc1f44bba6fb5366d98b8973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:57:57 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n",
      "2025-05-05 21:57:57,374 - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n",
      "21:57:57 - cmdstanpy - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:57:57,505 - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n",
      "2025-05-05 21:57:59,449 - INFO - Prophet Metrics (changepoint_prior_scale=0.05): {'RMSE': 4.268181115498104, 'MAE': 3.4594639534728953, 'MAPE': 1.6560626873078026}\n",
      "2025-05-05 21:57:59,450 - INFO - Prophet Metrics (changepoint_prior_scale=0.05): {'RMSE': 4.268181115498104, 'MAE': 3.4594639534728953, 'MAPE': 1.6560626873078026}\n",
      "2025-05-05 21:57:59,451 - INFO - Prophet input DataFrame columns: ['Close', 'Volume', 'Ticker', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']\n",
      "2025-05-05 21:57:59,469 - INFO - Prophet input data summary:\n",
      "                        ds           y  Diluted EPS  Free Cash Flow  Net Debt  \\\n",
      "count                  726  726.000000        726.0           726.0     726.0   \n",
      "mean   2024-05-04 12:00:00  202.270620          0.0             0.0       0.0   \n",
      "min    2023-05-08 00:00:00  165.000000          0.0             0.0       0.0   \n",
      "25%    2023-11-05 06:00:00  180.950000          0.0             0.0       0.0   \n",
      "50%    2024-05-04 12:00:00  193.500000          0.0             0.0       0.0   \n",
      "75%    2024-11-01 18:00:00  225.860000          0.0             0.0       0.0   \n",
      "max    2025-05-02 00:00:00  259.020000          0.0             0.0       0.0   \n",
      "std                    NaN   24.831609          0.0             0.0       0.0   \n",
      "\n",
      "       EBITDA  Sentiment_Score  \n",
      "count   726.0       726.000000  \n",
      "mean      0.0         0.004758  \n",
      "min       0.0         0.000000  \n",
      "25%       0.0         0.000000  \n",
      "50%       0.0         0.000000  \n",
      "75%       0.0         0.000000  \n",
      "max       0.0         0.804225  \n",
      "std       0.0         0.058091  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b197fb0eed6c4402985240bcf9e5dc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57def0bfe95d492faa6cb1b79ca29b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e3612b26184ca6ab03055ec0a8886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ae31ef93a948dcb5a52e3dc02c9774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:59:05 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n",
      "2025-05-05 21:59:05,077 - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n",
      "21:59:05 - cmdstanpy - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n",
      "2025-05-05 21:59:05,143 - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:59:07,098 - INFO - Prophet Metrics (changepoint_prior_scale=0.1): {'RMSE': 5.148379687563651, 'MAE': 4.061348219056567, 'MAPE': 1.941080155714326}\n",
      "2025-05-05 21:59:07,100 - INFO - Prophet Metrics (changepoint_prior_scale=0.1): {'RMSE': 5.148379687563651, 'MAE': 4.061348219056567, 'MAPE': 1.941080155714326}\n",
      "2025-05-05 21:59:07,102 - INFO - Prophet input DataFrame columns: ['Close', 'Volume', 'Ticker', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']\n",
      "2025-05-05 21:59:07,139 - INFO - Prophet input data summary:\n",
      "                        ds           y  Diluted EPS  Free Cash Flow  Net Debt  \\\n",
      "count                  726  726.000000        726.0           726.0     726.0   \n",
      "mean   2024-05-04 12:00:00  202.270620          0.0             0.0       0.0   \n",
      "min    2023-05-08 00:00:00  165.000000          0.0             0.0       0.0   \n",
      "25%    2023-11-05 06:00:00  180.950000          0.0             0.0       0.0   \n",
      "50%    2024-05-04 12:00:00  193.500000          0.0             0.0       0.0   \n",
      "75%    2024-11-01 18:00:00  225.860000          0.0             0.0       0.0   \n",
      "max    2025-05-02 00:00:00  259.020000          0.0             0.0       0.0   \n",
      "std                    NaN   24.831609          0.0             0.0       0.0   \n",
      "\n",
      "       EBITDA  Sentiment_Score  \n",
      "count   726.0       726.000000  \n",
      "mean      0.0         0.004758  \n",
      "min       0.0         0.000000  \n",
      "25%       0.0         0.000000  \n",
      "50%       0.0         0.000000  \n",
      "75%       0.0         0.000000  \n",
      "max       0.0         0.804225  \n",
      "std       0.0         0.058091  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7669529ab85f4411a5ea3809697dbc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d39c14791b451fa5d77230eca55b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78acde9e82524b11856ec2ce510d6f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e1fdc1b67b433caaf2453360b143d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:00:12 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n",
      "2025-05-05 22:00:12,747 - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "\tException: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in 'prophet.stan', line 137, column 2 to line 142, column 4)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:00:12 - cmdstanpy - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n",
      "2025-05-05 22:00:12,869 - WARNING - Some chains may have failed to converge.\n",
      "\tChain 1 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 2 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 3 had 150 iterations at max treedepth (100.0%)\n",
      "\tChain 4 had 150 iterations at max treedepth (100.0%)\n",
      "\tUse the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n",
      "2025-05-05 22:00:14,979 - INFO - Prophet Metrics (changepoint_prior_scale=0.5): {'RMSE': 5.186403168276778, 'MAE': 4.1981014741654485, 'MAPE': 2.009013101538352}\n",
      "2025-05-05 22:00:14,983 - INFO - Prophet Metrics (changepoint_prior_scale=0.5): {'RMSE': 5.186403168276778, 'MAE': 4.1981014741654485, 'MAPE': 2.009013101538352}\n",
      "2025-05-05 22:00:14,984 - INFO - Best Prophet changepoint_prior_scale: 0.05\n",
      "2025-05-05 22:00:14,986 - INFO - Best Prophet Metrics: {'RMSE': 4.268181115498104, 'MAE': 3.4594639534728953, 'MAPE': 1.6560626873078026}\n"
     ]
    }
   ],
   "source": [
    "# Prophet forecast with tuning\n",
    "prophet_forecast, prophet_metrics, prophet_forecast_df, prophet_scale = tune_prophet(data, forecast_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185a56",
   "metadata": {},
   "source": [
    "**Walk-forward validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927ee1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "2025-05-05 22:00:45,869 - INFO - Walk-Forward Validation Results: {'ARIMA': {'RMSE': 6.231899940369896, 'MAE': 4.940143565695503, 'MAPE': 2.2761371502769805}, 'Prophet': {'RMSE': 7.593562992412941, 'MAE': 7.155568344548186, 'MAPE': 3.2610302105910867}}\n"
     ]
    }
   ],
   "source": [
    "avg_metrics = walk_forward_validation(data, forecast_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30649a1",
   "metadata": {},
   "source": [
    "**Backtesting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be3d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "2025-05-05 22:00:48,929 - INFO - Backtest input lengths - Data: 719, Predictions: 719\n",
      "2025-05-05 22:00:48,934 - ERROR - Error in backtesting: Can only compare identically-labeled Series objects\n",
      "2025-05-05 22:00:49,434 - INFO - Backtest input lengths - Data: 719, Predictions: 719\n",
      "2025-05-05 22:00:49,434 - ERROR - Error in backtesting: Can only compare identically-labeled Series objects\n"
     ]
    }
   ],
   "source": [
    "# Backtesting\n",
    "if len(data) >= 100:\n",
    "    # ARIMA historical predictions\n",
    "    arima_model = auto_arima(data['Close'][:-forecast_horizon], seasonal=False, max_p=7, max_q=7, max_d=2)\n",
    "    arima_fit = ARIMA(data['Close'][:-forecast_horizon], order=arima_model.order).fit()\n",
    "    arima_hist_pred = arima_fit.predict(start=0, end=len(data)-forecast_horizon-1)\n",
    "    arima_backtest_results, arima_backtest_df = backtest_strategy(data.iloc[:-forecast_horizon], arima_hist_pred, 'ARIMA')\n",
    "    \n",
    "    # Prophet historical predictions\n",
    "    train_data = data.iloc[:-forecast_horizon]\n",
    "    prophet_df = train_data.reset_index()[['Date', 'Close', 'Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']]\n",
    "    prophet_df = prophet_df.drop_duplicates(subset='Date')\n",
    "    prophet_df = prophet_df.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "    \n",
    "    prophet_model = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True,\n",
    "                            changepoint_prior_scale=prophet_scale, mcmc_samples=0)\n",
    "    for regressor in ['Diluted EPS', 'Free Cash Flow', 'Net Debt', 'EBITDA', 'Sentiment_Score']:\n",
    "        prophet_model.add_regressor(regressor)\n",
    "    prophet_model.fit(prophet_df)\n",
    "    \n",
    "    prophet_pred_df = prophet_model.predict(prophet_df)\n",
    "    prophet_pred_df = prophet_pred_df.set_index('ds').reindex(train_data.index, method='ffill')\n",
    "    prophet_hist_pred = prophet_pred_df['yhat']\n",
    "    \n",
    "    prophet_backtest_results, prophet_backtest_df = backtest_strategy(train_data, prophet_hist_pred, 'Prophet')\n",
    "else:\n",
    "    arima_backtest_results, arima_backtest_df = None, None\n",
    "    prophet_backtest_results, prophet_backtest_df = None, None\n",
    "    logging.warning(f\"Insufficient data for backtesting {ticker}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a44dd9",
   "metadata": {},
   "source": [
    "**Plot predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d27191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plot_predictions(data, arima_forecast, prophet_forecast, prophet_forecast_df,\n",
    "                arima_backtest_df, prophet_backtest_df, ticker, forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898de895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 21:18:53,810 - INFO - Saved predictions for AAPL\n",
      "2025-05-05 21:18:53,814 - INFO - Saved metrics for AAPL\n",
      "2025-05-05 21:18:53,819 - INFO - Saved summary results\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "if arima_forecast is not None and prophet_forecast is not None:\n",
    "    future_dates = [data.index[-1] + timedelta(days=i+1) for i in range(forecast_horizon)]\n",
    "    pred_df = pd.DataFrame({\n",
    "        'Date': future_dates,\n",
    "        'ARIMA_Prediction': arima_forecast,\n",
    "        'Prophet_Prediction': prophet_forecast\n",
    "    })\n",
    "    pred_df.to_csv(data_dir / f'{ticker}_stock_price_predictions.csv', index=False)\n",
    "    logging.info(f\"Saved predictions for {ticker}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['ARIMA', 'Prophet'],\n",
    "    'RMSE': [arima_metrics.get('RMSE', np.nan), prophet_metrics.get('RMSE', np.nan)],\n",
    "    'MAE': [arima_metrics.get('MAE', np.nan), prophet_metrics.get('MAE', np.nan)],\n",
    "    'MAPE': [arima_metrics.get('MAPE', np.nan), prophet_metrics.get('MAPE', np.nan)],\n",
    "    'Best Parameters': [f\"Order: {arima_order}\", f\"changepoint_prior_scale: {prophet_scale or 0.05}\"]\n",
    "})\n",
    "metrics_df.to_csv(data_dir / f'{ticker}_model_metrics.csv', index=False)\n",
    "logging.info(f\"Saved metrics for {ticker}\")\n",
    "\n",
    "# Save backtest results\n",
    "if arima_backtest_results and prophet_backtest_results:\n",
    "    backtest_df = pd.DataFrame({\n",
    "        'Model': ['ARIMA', 'Prophet'],\n",
    "        'Cumulative Return (%)': [arima_backtest_results['Cumulative Return (%)'], \n",
    "                                prophet_backtest_results['Cumulative Return (%)']],\n",
    "        'Number of Trades': [arima_backtest_results['Number of Trades'], \n",
    "                            prophet_backtest_results['Number of Trades']]\n",
    "    })\n",
    "    backtest_df.to_csv(data_dir / f'{ticker}_backtest_results.csv', index=False)\n",
    "    logging.info(f\"Saved backtest results for {ticker}\")\n",
    "\n",
    "# Select best model\n",
    "best_model = 'Prophet' if avg_metrics['Prophet']['RMSE'] < avg_metrics['ARIMA']['RMSE'] else 'ARIMA'\n",
    "results.append({'Ticker': ticker, 'Best_Model': best_model, 'Metrics': avg_metrics})\n",
    "\n",
    "# Save summary\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(data_dir / 'summary_results.csv', index=False)\n",
    "logging.info(\"Saved summary results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
