{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e964fad",
   "metadata": {},
   "source": [
    "# **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d855c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from newsapi import NewsApiClient\n",
    "from fredapi import Fred\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, ttk\n",
    "from tkcalendar import Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c1cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_date(date_obj):\n",
    "    \"\"\"\n",
    "    Validate and convert date object to datetime in US/Eastern timezone.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        eastern = pytz.timezone('US/Eastern')\n",
    "        return date_obj.replace(tzinfo=eastern)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def validate_interval(interval):\n",
    "    \"\"\"\n",
    "    Validate the interval against supported yfinance intervals.\n",
    "    \"\"\"\n",
    "    valid_intervals = ['1m', '5m', '30m', '1d', '1wk', '1mo']\n",
    "    return interval if interval in valid_intervals else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15695331",
   "metadata": {},
   "source": [
    "### **Fetch and Clean historical stock data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "946de1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_stock_data(tickers, start_date, end_date, interval='5m'):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data for a list of tickers at specified interval.\n",
    "    \"\"\"\n",
    "    historical_data = []\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    \n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    if isinstance(start_date, datetime):\n",
    "        start_date = start_date.astimezone(eastern)\n",
    "    if isinstance(end_date, datetime):\n",
    "        end_date = end_date.astimezone(eastern)\n",
    "    \n",
    "    try:\n",
    "        df = yf.download(tickers, start=start_date, end=end_date, interval=interval)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"No data returned. Check if the date range includes trading hours or if tickers are valid.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if len(tickers) == 1:\n",
    "            ticker = tickers[0]\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = [col[0] for col in df.columns]\n",
    "            \n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"Missing required columns for {ticker}: {missing_columns}\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            df = df.reset_index()\n",
    "            if 'Date' not in df.columns:\n",
    "                if df.columns[0] in ['Datetime', 'index', 'DateTime']:\n",
    "                    df = df.rename(columns={df.columns[0]: 'Date'})\n",
    "                else:\n",
    "                    print(f\"Unexpected index column: {df.columns[0]}\")\n",
    "                    return pd.DataFrame()\n",
    "            \n",
    "            df['Ticker'] = ticker\n",
    "            df['Adj Close'] = df.get('Adj Close', df['Close'])\n",
    "            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Ticker']]\n",
    "            print(f\"Fetched {len(df)} data points for {ticker} at {interval} interval\")\n",
    "            historical_data.append(df)\n",
    "        else:\n",
    "            for ticker in tickers:\n",
    "                if ticker not in df.columns.get_level_values(1):\n",
    "                    print(f\"No data returned for {ticker}\")\n",
    "                    continue\n",
    "                ticker_df = df.xs(ticker, level=1, axis=1).copy()\n",
    "                if ticker_df.empty:\n",
    "                    print(f\"No data returned for {ticker}\")\n",
    "                    continue\n",
    "                \n",
    "                missing_columns = [col for col in required_columns if col not in ticker_df.columns]\n",
    "                if missing_columns:\n",
    "                    print(f\"Missing required columns for {ticker}: {missing_columns}\")\n",
    "                    continue\n",
    "                \n",
    "                ticker_df = ticker_df.reset_index()\n",
    "                if 'Date' not in ticker_df.columns:\n",
    "                    if ticker_df.columns[0] in ['Datetime', 'index', 'DateTime']:\n",
    "                        ticker_df = ticker_df.rename(columns={ticker_df.columns[0]: 'Date'})\n",
    "                    else:\n",
    "                        print(f\"Unexpected index column for {ticker}: {ticker_df.columns[0]}\")\n",
    "                        continue\n",
    "                \n",
    "                ticker_df['Ticker'] = ticker\n",
    "                ticker_df['Adj Close'] = ticker_df.get('Adj Close', ticker_df['Close'])\n",
    "                ticker_df = ticker_df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Ticker']]\n",
    "                print(f\"Fetched {len(ticker_df)} data points for {ticker} at {interval} interval\")\n",
    "                historical_data.append(ticker_df)\n",
    "        \n",
    "        if not historical_data:\n",
    "            print(\"No data collected for any tickers. Possible non-trading day or invalid tickers.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        combined_df = pd.concat(historical_data, ignore_index=True)\n",
    "        combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "        return combined_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_data(data):\n",
    "    \"\"\"\n",
    "    Clean stock data by handling missing values and ensuring data quality.\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"No data to clean.\")\n",
    "        return data\n",
    "\n",
    "    required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Ticker']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        print(\"Missing required columns.\")\n",
    "        return data\n",
    "\n",
    "    price_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "    data[price_columns] = data[price_columns].ffill()\n",
    "    data['Volume'] = data['Volume'].fillna(0)\n",
    "    data = data.dropna()\n",
    "    data = data.drop_duplicates(subset=['Ticker', 'Date'], keep='last')\n",
    "    \n",
    "    for col in price_columns + ['Volume']:\n",
    "        data[col] = data[col].clip(lower=0)\n",
    "\n",
    "    data['Price_Change'] = data.groupby('Ticker')['Close'].pct_change()\n",
    "    data = data[data['Price_Change'].abs() < 0.05]\n",
    "    data = data.drop(columns=['Price_Change'], errors='ignore')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf85fa",
   "metadata": {},
   "source": [
    "# **Fetch news headlines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2eeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news_data(tickers, api_key, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch news articles including company-specific, global, and political news.\n",
    "    \"\"\"\n",
    "    newsapi = NewsApiClient(api_key=api_key)\n",
    "    news_data = []\n",
    "    \n",
    "    if isinstance(start_date, datetime):\n",
    "        start_date = start_date.astimezone(pytz.UTC)\n",
    "    if isinstance(end_date, datetime):\n",
    "        end_date = end_date.astimezone(pytz.UTC)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            company_query = f\"{ticker} stock\"\n",
    "            company_articles = newsapi.get_everything(\n",
    "                q=company_query,\n",
    "                from_param=start_date.strftime('%Y-%m-%d'),\n",
    "                to=end_date.strftime('%Y-%m-%d'),\n",
    "                language='en',\n",
    "                sort_by='publishedAt'\n",
    "            )\n",
    "            for article in company_articles['articles']:\n",
    "                news_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Date': pd.to_datetime(article['publishedAt']),\n",
    "                    'Title': article['title'],\n",
    "                    'Description': article['description'] or '',\n",
    "                    'Source': article['source']['name'],\n",
    "                    'URL': article['url'],\n",
    "                    'Category': 'Company'\n",
    "                })\n",
    "            \n",
    "            global_query = f\"{ticker} industry OR global economy OR political {ticker}\"\n",
    "            global_articles = newsapi.get_everything(\n",
    "                q=global_query,\n",
    "                from_param=start_date.strftime('%Y-%m-%d'),\n",
    "                to=end_date.strftime('%Y-%m-%d'),\n",
    "                language='en',\n",
    "                sort_by='publishedAt'\n",
    "            )\n",
    "            for article in global_articles['articles']:\n",
    "                news_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Date': pd.to_datetime(article['publishedAt']),\n",
    "                    'Title': article['title'],\n",
    "                    'Description': article['description'] or '',\n",
    "                    'Source': article['source']['name'],\n",
    "                    'URL': article['url'],\n",
    "                    'Category': 'Global/Political'\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news for {ticker}: {e}\")\n",
    "    \n",
    "    news_df = pd.DataFrame(news_data)\n",
    "    if not news_df.empty:\n",
    "        print(f\"Fetched {len(news_df)} news articles for {tickers}\")\n",
    "        print(f\"News columns: {news_df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(f\"No news articles found for {tickers} in the specified date range.\")\n",
    "    return news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffc2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_info(tickers):\n",
    "    \"\"\"\n",
    "    Fetch stock-related data (ISIN, history metadata, dividends, splits, actions, capital gains).\n",
    "    \"\"\"\n",
    "    stock_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # ISIN\n",
    "            isin = pd.DataFrame({'Ticker': [ticker], 'ISIN': [stock.get_isin()]})\n",
    "            stock_data.append(isin)\n",
    "            \n",
    "            # History Metadata\n",
    "            history_metadata = pd.DataFrame({'Ticker': [ticker], 'History Metadata': [stock.get_history_metadata()]})\n",
    "            stock_data.append(history_metadata)\n",
    "            \n",
    "            # Dividends\n",
    "            dividends = stock.get_dividends(start=\"1900-01-01\", end=datetime.now().strftime('%Y-%m-%d')).reset_index()\n",
    "            dividends['Ticker'] = ticker\n",
    "            stock_data.append(dividends)\n",
    "            \n",
    "            # Splits\n",
    "            splits = stock.get_splits(start=\"1900-01-01\", end=datetime.now().strftime('%Y-%m-%d')).reset_index()\n",
    "            splits['Ticker'] = ticker\n",
    "            stock_data.append(splits)\n",
    "            \n",
    "            # Actions\n",
    "            actions = stock.get_actions().reset_index()\n",
    "            actions['Ticker'] = ticker\n",
    "            stock_data.append(actions)\n",
    "            \n",
    "            # Capital Gains (if available)\n",
    "            capital_gains = stock.get_capital_gains().reset_index() if stock.get_capital_gains() is not None else pd.DataFrame()\n",
    "            if not capital_gains.empty:\n",
    "                capital_gains['Ticker'] = ticker\n",
    "                stock_data.append(capital_gains)\n",
    "            \n",
    "            print(f\"Fetched stock info for {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching stock info for {ticker}: {e}\")\n",
    "    \n",
    "    if stock_data:\n",
    "        combined_stock = pd.concat(stock_data, ignore_index=True)\n",
    "        combined_stock.to_csv(f\"stock_info_{ticker}.csv\", index=False)\n",
    "        print(f\"Saved stock info for {ticker} to stock_info_{ticker}.csv\")\n",
    "        print(f\"Stock info columns: {combined_stock.columns.tolist()}\")\n",
    "        return combined_stock\n",
    "    else:\n",
    "        print(\"No stock info retrieved.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd8ed374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_financial_reports(tickers):\n",
    "    \"\"\"\n",
    "    Fetch financial statements and related data for tickers.\n",
    "    \"\"\"\n",
    "    financial_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Income Statement\n",
    "            income_stmt = stock.get_income_stmt().reset_index()\n",
    "            income_stmt['Ticker'] = ticker\n",
    "            income_stmt['Statement'] = 'Income Statement'\n",
    "            financial_data.append(income_stmt)\n",
    "            income_stmt.to_csv(f\"income_statement_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved income statement for {ticker} to income_statement_{ticker}.csv\")\n",
    "            \n",
    "            # Quarterly Income Statement\n",
    "            quarterly_income = stock.get_quarterly_income_stmt().reset_index()\n",
    "            quarterly_income['Ticker'] = ticker\n",
    "            quarterly_income['Statement'] = 'Quarterly Income Statement'\n",
    "            financial_data.append(quarterly_income)\n",
    "            quarterly_income.to_csv(f\"quarterly_income_statement_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved quarterly income statement for {ticker} to quarterly_income_statement_{ticker}.csv\")\n",
    "            \n",
    "            # TTM Income Statement\n",
    "            ttm_income = stock.get_ttm_income_stmt().reset_index()\n",
    "            ttm_income['Ticker'] = ticker\n",
    "            ttm_income['Statement'] = 'TTM Income Statement'\n",
    "            financial_data.append(ttm_income)\n",
    "            ttm_income.to_csv(f\"ttm_income_statement_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved TTM income statement for {ticker} to ttm_income_statement_{ticker}.csv\")\n",
    "            \n",
    "            # Balance Sheet\n",
    "            balance_sheet = stock.get_balance_sheet().reset_index()\n",
    "            balance_sheet['Ticker'] = ticker\n",
    "            balance_sheet['Statement'] = 'Balance Sheet'\n",
    "            financial_data.append(balance_sheet)\n",
    "            balance_sheet.to_csv(f\"balance_sheet_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved balance sheet for {ticker} to balance_sheet_{ticker}.csv\")\n",
    "            \n",
    "            # Cash Flow\n",
    "            cash_flow = stock.get_cashflow().reset_index()\n",
    "            cash_flow['Ticker'] = ticker\n",
    "            cash_flow['Statement'] = 'Cash Flow'\n",
    "            financial_data.append(cash_flow)\n",
    "            cash_flow.to_csv(f\"cash_flow_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved cash flow for {ticker} to cash_flow_{ticker}.csv\")\n",
    "            \n",
    "            # Quarterly Cash Flow\n",
    "            quarterly_cashflow = stock.get_quarterly_cashflow().reset_index()\n",
    "            quarterly_cashflow['Ticker'] = ticker\n",
    "            quarterly_cashflow['Statement'] = 'Quarterly Cash Flow'\n",
    "            financial_data.append(quarterly_cashflow)\n",
    "            quarterly_cashflow.to_csv(f\"quarterly_cashflow_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved quarterly cash flow for {ticker} to quarterly_cashflow_{ticker}.csv\")\n",
    "            \n",
    "            # TTM Cash Flow\n",
    "            ttm_cashflow = stock.get_ttm_cashflow().reset_index()\n",
    "            ttm_cashflow['Ticker'] = ticker\n",
    "            ttm_cashflow['Statement'] = 'TTM Cash Flow'\n",
    "            financial_data.append(ttm_cashflow)\n",
    "            ttm_cashflow.to_csv(f\"ttm_cashflow_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved TTM cash flow for {ticker} to ttm_cashflow_{ticker}.csv\")\n",
    "            \n",
    "            # Earnings\n",
    "            earnings = stock.get_earnings().reset_index()\n",
    "            earnings['Ticker'] = ticker\n",
    "            earnings['Statement'] = 'Earnings'\n",
    "            financial_data.append(earnings)\n",
    "            earnings.to_csv(f\"earnings_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved earnings for {ticker} to earnings_{ticker}.csv\")\n",
    "            \n",
    "            # Calendar\n",
    "            calendar = stock.get_calendar().reset_index()\n",
    "            calendar['Ticker'] = ticker\n",
    "            calendar['Statement'] = 'Calendar'\n",
    "            financial_data.append(calendar)\n",
    "            calendar.to_csv(f\"calendar_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved calendar for {ticker} to calendar_{ticker}.csv\")\n",
    "            \n",
    "            # Earnings Dates\n",
    "            earnings_dates = stock.get_earnings_dates().reset_index()\n",
    "            earnings_dates['Ticker'] = ticker\n",
    "            earnings_dates['Statement'] = 'Earnings Dates'\n",
    "            financial_data.append(earnings_dates)\n",
    "            earnings_dates.to_csv(f\"earnings_dates_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved earnings dates for {ticker} to earnings_dates_{ticker}.csv\")\n",
    "            \n",
    "            # SEC Filings\n",
    "            sec_filings = stock.get_sec_filings().reset_index()\n",
    "            sec_filings['Ticker'] = ticker\n",
    "            sec_filings['Statement'] = 'SEC Filings'\n",
    "            financial_data.append(sec_filings)\n",
    "            sec_filings.to_csv(f\"sec_filings_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved SEC filings for {ticker} to sec_filings_{ticker}.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching financial reports for {ticker}: {e}\")\n",
    "    \n",
    "    if financial_data:\n",
    "        combined_financials = pd.concat(financial_data, ignore_index=True)\n",
    "        combined_financials.to_csv(f\"financial_reports_{ticker}.csv\", index=False)\n",
    "        print(f\"Saved combined financial reports for {ticker} to financial_reports_{ticker}.csv\")\n",
    "        print(f\"Financial reports columns: {combined_financials.columns.tolist()}\")\n",
    "        return combined_financials\n",
    "    else:\n",
    "        print(\"No financial data retrieved.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d73abed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_analysis_and_holdings(tickers):\n",
    "    \"\"\"\n",
    "    Fetch analysis and holdings data for tickers.\n",
    "    \"\"\"\n",
    "    analysis_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Analyst Price Targets\n",
    "            analyst_price_targets = pd.DataFrame(stock.get_analyst_price_targets()).T.reset_index()\n",
    "            analyst_price_targets['Ticker'] = ticker\n",
    "            analysis_data.append(analyst_price_targets)\n",
    "            analyst_price_targets.to_csv(f\"analyst_price_targets_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved analyst price targets for {ticker} to analyst_price_targets_{ticker}.csv\")\n",
    "            \n",
    "            # Earnings Estimate\n",
    "            earnings_estimate = pd.DataFrame(stock.get_earnings_estimate()).T.reset_index()\n",
    "            earnings_estimate['Ticker'] = ticker\n",
    "            analysis_data.append(earnings_estimate)\n",
    "            earnings_estimate.to_csv(f\"earnings_estimate_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved earnings estimate for {ticker} to earnings_estimate_{ticker}.csv\")\n",
    "            \n",
    "            # Revenue Estimate\n",
    "            revenue_estimate = pd.DataFrame(stock.get_revenue_estimate()).T.reset_index()\n",
    "            revenue_estimate['Ticker'] = ticker\n",
    "            analysis_data.append(revenue_estimate)\n",
    "            revenue_estimate.to_csv(f\"revenue_estimate_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved revenue estimate for {ticker} to revenue_estimate_{ticker}.csv\")\n",
    "            \n",
    "            # Earnings History\n",
    "            earnings_history = pd.DataFrame(stock.get_earnings_history()).reset_index()\n",
    "            earnings_history['Ticker'] = ticker\n",
    "            analysis_data.append(earnings_history)\n",
    "            earnings_history.to_csv(f\"earnings_history_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved earnings history for {ticker} to earnings_history_{ticker}.csv\")\n",
    "            \n",
    "            # EPS Trend\n",
    "            eps_trend = pd.DataFrame(stock.get_eps_trend()).T.reset_index()\n",
    "            eps_trend['Ticker'] = ticker\n",
    "            analysis_data.append(eps_trend)\n",
    "            eps_trend.to_csv(f\"eps_trend_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved EPS trend for {ticker} to eps_trend_{ticker}.csv\")\n",
    "            \n",
    "            # EPS Revisions\n",
    "            eps_revisions = pd.DataFrame(stock.get_eps_revisions()).T.reset_index()\n",
    "            eps_revisions['Ticker'] = ticker\n",
    "            analysis_data.append(eps_revisions)\n",
    "            eps_revisions.to_csv(f\"eps_revisions_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved EPS revisions for {ticker} to eps_revisions_{ticker}.csv\")\n",
    "            \n",
    "            # Growth Estimates\n",
    "            growth_estimates = pd.DataFrame(stock.get_growth_estimates()).T.reset_index()\n",
    "            growth_estimates['Ticker'] = ticker\n",
    "            analysis_data.append(growth_estimates)\n",
    "            growth_estimates.to_csv(f\"growth_estimates_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved growth estimates for {ticker} to growth_estimates_{ticker}.csv\")\n",
    "            \n",
    "            # Funds Data\n",
    "            funds_data = pd.DataFrame(stock.get_funds_data()).T.reset_index()\n",
    "            funds_data['Ticker'] = ticker\n",
    "            analysis_data.append(funds_data)\n",
    "            funds_data.to_csv(f\"funds_data_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved funds data for {ticker} to funds_data_{ticker}.csv\")\n",
    "            \n",
    "            # Insider Purchases\n",
    "            insider_purchases = stock.get_insider_purchases().reset_index()\n",
    "            insider_purchases['Ticker'] = ticker\n",
    "            analysis_data.append(insider_purchases)\n",
    "            insider_purchases.to_csv(f\"insider_purchases_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved insider purchases for {ticker} to insider_purchases_{ticker}.csv\")\n",
    "            \n",
    "            # Insider Transactions\n",
    "            insider_transactions = stock.get_insider_transactions().reset_index()\n",
    "            insider_transactions['Ticker'] = ticker\n",
    "            analysis_data.append(insider_transactions)\n",
    "            insider_transactions.to_csv(f\"insider_transactions_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved insider transactions for {ticker} to insider_transactions_{ticker}.csv\")\n",
    "            \n",
    "            # Insider Roster Holders\n",
    "            insider_roster_holders = stock.get_insider_roster_holders().reset_index()\n",
    "            insider_roster_holders['Ticker'] = ticker\n",
    "            analysis_data.append(insider_roster_holders)\n",
    "            insider_roster_holders.to_csv(f\"insider_roster_holders_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved insider roster holders for {ticker} to insider_roster_holders_{ticker}.csv\")\n",
    "            \n",
    "            # Major Holders\n",
    "            major_holders = stock.get_major_holders().reset_index()\n",
    "            major_holders['Ticker'] = ticker\n",
    "            analysis_data.append(major_holders)\n",
    "            major_holders.to_csv(f\"major_holders_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved major holders for {ticker} to major_holders_{ticker}.csv\")\n",
    "            \n",
    "            # Institutional Holders\n",
    "            institutional_holders = stock.get_institutional_holders().reset_index()\n",
    "            institutional_holders['Ticker'] = ticker\n",
    "            analysis_data.append(institutional_holders)\n",
    "            institutional_holders.to_csv(f\"institutional_holders_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved institutional holders for {ticker} to institutional_holders_{ticker}.csv\")\n",
    "            \n",
    "            # Mutual Fund Holders\n",
    "            mutualfund_holders = stock.get_mutualfund_holders().reset_index()\n",
    "            mutualfund_holders['Ticker'] = ticker\n",
    "            analysis_data.append(mutualfund_holders)\n",
    "            mutualfund_holders.to_csv(f\"mutualfund_holders_{ticker}.csv\", index=False)\n",
    "            print(f\"Saved mutual fund holders for {ticker} to mutualfund_holders_{ticker}.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching analysis and holdings for {ticker}: {e}\")\n",
    "    \n",
    "    if analysis_data:\n",
    "        combined_analysis = pd.concat(analysis_data, ignore_index=True)\n",
    "        combined_analysis.to_csv(f\"analysis_and_holdings_{ticker}.csv\", index=False)\n",
    "        print(f\"Saved combined analysis and holdings for {ticker} to analysis_and_holdings_{ticker}.csv\")\n",
    "        print(f\"Analysis and holdings columns: {combined_analysis.columns.tolist()}\")\n",
    "        return combined_analysis\n",
    "    else:\n",
    "        print(\"No analysis and holdings data retrieved.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c9664",
   "metadata": {},
   "source": [
    "# **Exploratory data analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9900308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df, financial_df, news_df, analysis_df, info_df, ticker='AAPL', interval='5m'):\n",
    "    \"\"\"\n",
    "    Perform EDA including stock data, financial reports, news, analysis, and info.\n",
    "    \"\"\"\n",
    "    ticker_df = df[df['Ticker'] == ticker].copy()\n",
    "    \n",
    "    if ticker_df.empty:\n",
    "        print(f\"No stock data available for ticker {ticker}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nSummary Statistics for {ticker} Stock Data:\")\n",
    "    print(ticker_df.describe())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24797d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gui():\n",
    "    \"\"\"\n",
    "    Create a tkinter GUI to fetch all available financial data.\n",
    "    \"\"\"\n",
    "    def open_calendar(is_start_date):\n",
    "        top = tk.Toplevel(root)\n",
    "        top.title(\"Select Date\")\n",
    "        top.geometry(\"300x300\")\n",
    "        \n",
    "        cal = Calendar(top, selectmode='day', date_pattern='yyyy-mm-dd')\n",
    "        cal.pack(pady=10)\n",
    "        \n",
    "        def select_date():\n",
    "            selected_date = cal.get_date()\n",
    "            if is_start_date:\n",
    "                start_date_var.set(selected_date)\n",
    "            else:\n",
    "                end_date_var.set(selected_date)\n",
    "            error_label.config(text=\"\", fg=\"red\")\n",
    "            top.destroy()\n",
    "        \n",
    "        tk.Button(top, text=\"Select\", command=select_date).pack(pady=10)\n",
    "\n",
    "    def submit():\n",
    "        start_date_str = start_date_var.get()\n",
    "        end_date_str = end_date_var.get()\n",
    "        interval = interval_var.get()\n",
    "        \n",
    "        error_label.config(text=\"\", fg=\"red\")\n",
    "        \n",
    "        try:\n",
    "            start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "            start_date = validate_date(start_date)\n",
    "            end_date = validate_date(end_date)\n",
    "        except ValueError:\n",
    "            error_label.config(text=\"Invalid date format. Use YYYY-MM-DD.\", fg=\"red\")\n",
    "            return\n",
    "        \n",
    "        if start_date is None or end_date is None:\n",
    "            error_label.config(text=\"Invalid date selection. Please select valid dates.\", fg=\"red\")\n",
    "            return\n",
    "        if not validate_interval(interval):\n",
    "            error_label.config(\"Invalid interval. Choose from dropdown.\", fg=\"red\")\n",
    "            return\n",
    "        if end_date < start_date:\n",
    "            error_label.config(text=\"End date must be on or after start date.\", fg=\"red\")\n",
    "            return\n",
    "        \n",
    "        range_limits = {\n",
    "            '1m': 7, '5m': 60, '30m': 60, '1d': 730, '1wk': 1825, '1mo': 7300}\n",
    "        \n",
    "        max_days = range_limits.get(interval, 60)\n",
    "        days_diff = (end_date - start_date).days\n",
    "        if days_diff > max_days:\n",
    "            error_label.config(text=f\"{interval} interval limited to {max_days} days.\", fg=\"red\")\n",
    "            return\n",
    "        \n",
    "        root.destroy()\n",
    "        \n",
    "        tickers = ['AAPL']\n",
    "        news_api_key = '6b423b01d98e47859e2ecbc296aa9b2b'\n",
    "        \n",
    "        print(f\"\\nFetching stock data for {tickers} from {start_date.date()} to {end_date.date()} at {interval} interval...\")\n",
    "        try:\n",
    "            historical_data = fetch_historical_stock_data(tickers, start_date, end_date, interval)\n",
    "            if historical_data.empty:\n",
    "                raise ValueError(\"No historical data retrieved\")\n",
    "\n",
    "            cleaned_data = clean_stock_data(historical_data)\n",
    "            cleaned_data.to_csv(\"cleaned_stock_data.csv\", index=False)\n",
    "            \n",
    "            \n",
    "            print(f\"\\nFetching financial reports for {tickers}...\")\n",
    "            financial_data = fetch_financial_reports(tickers)\n",
    "            if not financial_data.empty:\n",
    "                print(\"Financial reports saved to respective ticker files\")\n",
    "            \n",
    "            print(f\"\\nFetching analysis and holdings for {tickers}...\")\n",
    "            analysis_data = fetch_analysis_and_holdings(tickers)\n",
    "            if not analysis_data.empty:\n",
    "                print(\"Analysis and holdings saved to respective ticker files\")\n",
    "            \n",
    "            print(f\"\\nFetching info and fast info for {tickers}...\")\n",
    "            info_data = fetch_info_and_fast_info(tickers)\n",
    "            if not info_data.empty:\n",
    "                print(\"Info and fast info saved to respective ticker files\")\n",
    "            \n",
    "            print(f\"\\nFetching news data for {tickers} from {start_date.date()} to {end_date.date()}...\")\n",
    "            news_data = fetch_news_data(tickers, news_api_key, start_date, end_date)\n",
    "            if not news_data.empty:\n",
    "                news_data.to_csv(\"news_data.csv\", index=False)\n",
    "                print(\"News data saved to news_data.csv\")\n",
    "            \n",
    "            print(\"\\nPerforming exploratory data analysis...\")\n",
    "            perform_eda(cleaned_data, financial_data, news_data, analysis_data, info_data, ticker='AAPL', interval=interval)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data: {e}\")\n",
    "            tk.Tk().withdraw()\n",
    "            messagebox.showerror(\"Error\", f\"Error processing data: {e}\")\n",
    "\n",
    "    def cancel():\n",
    "        root.destroy()\n",
    "\n",
    "    def clear_error_on_interaction(*args):\n",
    "        error_label.config(text=\"\", fg=\"red\")\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Stock Data Input\")\n",
    "    root.geometry(\"400x400\")\n",
    "    \n",
    "    tk.Label(root, text=\"Start Date:\").pack(pady=10)\n",
    "    start_date_var = tk.StringVar(value=datetime.now().strftime('%Y-%m-%d'))\n",
    "    start_date_entry = tk.Entry(root, textvariable=start_date_var, state='readonly')\n",
    "    start_date_entry.pack()\n",
    "    tk.Button(root, text=\"Select Start Date\", command=lambda: open_calendar(True)).pack(pady=5)\n",
    "    start_date_var.trace('w', clear_error_on_interaction)\n",
    "    \n",
    "    tk.Label(root, text=\"End Date:\").pack(pady=10)\n",
    "    end_date_var = tk.StringVar(value=datetime.now().strftime('%Y-%m-%d'))\n",
    "    end_date_entry = tk.Entry(root, textvariable=end_date_var, state='readonly')\n",
    "    end_date_entry.pack()\n",
    "    tk.Button(root, text=\"Select End Date\", command=lambda: open_calendar(False)).pack(pady=5)\n",
    "    end_date_var.trace('w', clear_error_on_interaction)\n",
    "    \n",
    "    tk.Label(root, text=\"Interval:\").pack(pady=10)\n",
    "    interval_var = tk.StringVar(value='5m')\n",
    "    interval_menu = ttk.OptionMenu(root, interval_var, '5m', '1m', '5m', '30m', '1d', '1wk', '1mo')\n",
    "    interval_menu.pack()\n",
    "    interval_var.trace('w', clear_error_on_interaction)\n",
    "    \n",
    "    error_label = tk.Label(root, text=\"\", fg=\"red\", wraplength=350)\n",
    "    error_label.pack(pady=10)\n",
    "    \n",
    "    button_frame = tk.Frame(root)\n",
    "    button_frame.pack(pady=20)\n",
    "    tk.Button(button_frame, text=\"Submit\", command=submit).pack(side=tk.LEFT, padx=10)\n",
    "    tk.Button(button_frame, text=\"Cancel\", command=cancel).pack(side=tk.LEFT, padx=10)\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f105641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching stock data for ['AAPL'] from 2025-05-01 to 2025-05-02 at 30m interval...\n"
     ]
    }
   ],
   "source": [
    "# Ensure inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Launch GUI\n",
    "create_gui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
